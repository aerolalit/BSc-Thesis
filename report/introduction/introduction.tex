




    \subsection{Motivation of Research}
   	% \indent \indent The ability to predict the future data, based on past data, makes an important leverage that can push the organization forward.
    %   Time series forecasting is an important tool under this scenario where the goal is to predict the behaviour of complex systems solely by looking at patterns in past data. 
    %   A time series is a collection of periodic ordered observations  that appear  in multiple ranges of domains such as literature, agriculture, finance, media, etc., just to name a few \cite{paulo}. 
  	 %Time series are very complex because each observation is dependent upon the previous observations and is often influenced by more than one previous observations \cite{anne}. Hence, this research mainly focuses on the prediction of time series data in web traffic domain.\\
  	 The rapid development of Internet infrastructure, especially World Wide Web, has facilitated the communication among users and developers of websites. This has led to the consideration of resources allocation issues among the developer and maintainers of these websites. The availability of resources with less response time and  fewer failures is critical in these applications. One way to handle such issues is to predict the potential web traffic that a web system might receive. 
  	 Prediction of web traffic is important, especially for websites where bursty traffic is expected as this allows the system manager to allocate the resources appropriately  to control network congestion and improve the utilization rate of network resources \cite{learningToPredictWebTraffic, waveletAnalysis}. 
  	 %Online advertising business also depends upon the predicted web traffic because they need to distribute advertisements to the selected websites based on the predicted web traffic \cite{rojaa}.
  	 Web traffic prediction can also help to detect anomalies in the networks. Security attacks like Denial-of-Service, viruses, or even an irregular amount of spams can in theory be detected by comparing the real web traffic with the values predicted by forecasting algorithms \cite{Cortez06internettraffic, detectingNetworkAttacks}.\\
  	     Time series forecasting is an important task under this scenario where the goal is to predict the behaviour of complex systems solely by looking at patterns in past data. 
       A time series is a collection of periodic, ordered observations  that appear  in multiple ranges of domains such as literature, agriculture, finance, media, etc., just to name a few \cite{paulo}.  Time series are very complex because each observation is dependent upon and is often influenced by more than one previous observation \cite{anne}.\\
       Given a time series $\{s(t)\}^{M}_{t=1}$ of observations  of the variable $s$ at different points in time, there are two extreme situations that can occur.
       
       \begin{itemize}
           \item The value of $s$ at any time point $t+\Gamma$ is uniquely determined by the values of $s$ at time points that appeared before $t+\Gamma$, thus the time series can be described by Equation \eqref{eq:deterministicTS}.
           \begin{equation}\label{eq:deterministicTS}
               s(t+\Gamma) = h(s(t), s(t-\Gamma), s(t-m\Gamma)),
           \end{equation}
           where $h$ is some unknown function, $\Gamma$ is time delay between each observation of $s$, and $m$ is some integer value. One could derive the mapping $h$ from the initial values of $s$ provided that all the interaction between the elements in the system are clearly known.
           \item The value of $s(t)$ are independent random variables, so that past values have no influence on its future values. There is no deterministic mechanism underlying the data and the prediction is not possible at all.
       \end{itemize}
       In most practical cases ( example: web traffic), one has to deal with the time series that has properties somewhat between  these aforementioned extremes. For example, one could have the time series whose evolution is governed by a deterministic set of equation but the measurements are affected by noise. In this case a more appropriate model for it would be given by Equation \eqref{eq:betweenTS}.
       \begin{equation}\label{eq:betweenTS}
           s(t+\Gamma) = h(s(t), s(t-\Gamma), s(t-m\Gamma)) + \xi_t,
       \end{equation}
       where $\{ \xi \}_t$ is a set of random variables. If one could model the function $h$, the state of the system at time $t+\Gamma$ could be predicted within an accuracy that depends only on the variance of the random variables  $\{ \xi \}_t$ \cite{wpUsingANN}.
       Therefore, this research focuses on the prediction of the time series in a web domain, that is governed by a somewhat deterministic set of principles but are also affected by certain noise.
  	 As the prediction of web traffic is important due to aforementioned purposes, several research works have been done in this sector.\\
  
    \subsection{Prior Works}
    \indent
    Due to the importance of time series forecasting, several methods  such as the autoregressive integrated moving average (ARIMA) methodology \cite{TSanalysis}, Holt-Winters \cite{HOLT20045} and Neural Networks (NN) \cite{nonLinearSigProcessingNN, paulo} have been proposed. Holt-Winters was purposed for the series with trended and seasonal factors. The ARIMA approach is more complicated and requires steps such as model identification, estimation and validation. Each ARIMA model is based on linear combination of past values and/or errors. Neural Networks are connectionist models inspired by the behaviours of central nervous system and unlike previous methods, they can predict nonlinear time series \cite{Cortez06internettraffic}. Various statistical based methods have been used for forecasting time series especially in the finance domain \cite{methodsapplications}. The major drawback of most of these statistical models is that they consider that the time series are  generated from a linear process. However, most of the generated real world time series often consist of temporal and/or spatial variability and exhibit nonlinearity of underlying data generating process \cite{Panigrahi_timeseries}.
    
  
%     Traditionally these time series forecasting have been performed using various statistical-based methods \cite{methodsapplications}. The major drawback of most of these statistical models is that they consider the time series are generated from a linear process. However, most of the real world time series generated often consists of temporal and/or spatial variability and suffers from nonlinearity of underlying data generating process \cite{Panigrahi_timeseries}. 
%   In \cite{rojaa}, the author used both MLP and RNN for the prediction of web traffic and found out that MLP outperformed RNN. Despite extensive experimentation which involved tuning various parameters, the predictions produced by RNN were consistently poor in terms of accuracy \cite{rojaa}.
  Work in \cite{chakraborty} used Neural Network for forecasting time series. They compared their results with autoregressive moving average (ARMA)  model and found that Neural Network approach outperformed the ARMA model. In \cite{nonLinearSigProcessingNN}, the author used ARIMA, NN and Holt-Winters methods and found that ARIMA and NN outperformed the Holz-Winters method and overall NN approach was the best model. In \cite{comparisonREGARIMA}, the authors investigated two time series techniques, namely ARIMA and logistic regression for predicting road traffic. The traffic volumes forecasted  by these two models were compared with the actual traffic volumes on the standard error deviation. Their research concluded that the ARIMA method performed better for forecasting traffic volume. 

%   In \cite{winner}, the author uses Recurrent Neural Network sequence to sequence model where he used data features such as days of the week, year to year autocorrelation, quarter to quarter autocorrelation and page popularity to train his model.  His model outperformed all the model in a web traffic forecasting competition organised by Google on Kaggle (a platform for predictive modelling and analytics competitions).
%   Another participant of the same competition used Kalman filter to make the prediction \cite{otto}. % For the traffic generated by bots otto discarded weekly seasonality as bots donâ€™t care about weekly seasonality which improved his model performance\cite{otto}.

  All the methods that have been used before have some sort of disadvantages. Artificial Neural Networks (ANNs) require a complex training process; they may converge to a local minimum, have difficulty in determining the optimum network structure and experience fading memory (FM) \cite{wind}. Therefore, it is difficult to create a more accurate web traffic prediction model using ANNs.  Echo state networks (ESNs), a type of ANN proposed by Jaeger in 2001, can effectively solve some of the aforementioned problems with ANNs . In addition, ESN have short term memory and  the computational requirement for its training is lesser than training ANNs and Multilayer Perceptrons (MLPs) because  the connection weights of the reservoir are not changed and only weights from the reservoir to the output units are adapted, so training becomes a linear regression task \cite{ wind}.  Therefore, we have chosen ESNs for the prediction of web traffic.\\

  \subsection{Research Objective}
  Firstly, I would like to state that the goal of this project is to neither compete with the state of the art nor to compare the obtained results with those solutions. Rather, it is to see the possibility of the use of Echo State Network for web traffic forecasting tasks.
  The primary objectives for conducting this research are listed below:
  \begin{itemize}
  	\item To evaluate the performance of ESN for the prediction of web traffic.
%   	\item To optimize the parameters of ESN for its best performance.
	\item To find out what additional signal helps to improve the prediction task by ESN.
    \end{itemize}